{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "feab17a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping empty report for 16_IM-0389-1001.dcm.png: Findings and Impression are empty.\n",
      "Skipping empty report for 16_IM-0389-2001.dcm.png: Findings and Impression are empty.\n",
      "Skipping empty report for 614_IM-2200-4001.dcm.png: Findings and Impression are empty.\n",
      "Skipping empty report for 614_IM-2200-1001.dcm.png: Findings and Impression are empty.\n",
      "Skipping empty report for 673_IM-2247-3001.dcm.png: Findings and Impression are empty.\n",
      "Skipping empty report for 894_IM-2404-0001-0001.dcm.png: Findings and Impression are empty.\n",
      "Skipping empty report for 894_IM-2404-0001-0002.dcm.png: Findings and Impression are empty.\n",
      "Skipping empty report for 1137_IM-0093-12012.dcm.png: Findings and Impression are empty.\n",
      "Skipping empty report for 1137_IM-0093-4004.dcm.png: Findings and Impression are empty.\n",
      "Skipping empty report for 1142_IM-0096-1001.dcm.png: Findings and Impression are empty.\n",
      "Skipping empty report for 1142_IM-0096-2001.dcm.png: Findings and Impression are empty.\n",
      "Skipping empty report for 1147_IM-0099-4004.dcm.png: Findings and Impression are empty.\n",
      "Skipping empty report for 1293_IM-0192-4004.dcm.png: Findings and Impression are empty.\n",
      "Skipping empty report for 1297_IM-0195-4004.dcm.png: Findings and Impression are empty.\n",
      "Skipping empty report for 1297_IM-0195-1001.dcm.png: Findings and Impression are empty.\n",
      "Skipping empty report for 1536_IM-0347-0001-0001.dcm.png: Findings and Impression are empty.\n",
      "Skipping empty report for 1536_IM-0347-0001-0002.dcm.png: Findings and Impression are empty.\n",
      "Skipping empty report for 1536_IM-0347-0001-0003.dcm.png: Findings and Impression are empty.\n",
      "Skipping empty report for 1566_IM-0369-1001.dcm.png: Findings and Impression are empty.\n",
      "Skipping empty report for 1615_IM-0398-4004.dcm.png: Findings and Impression are empty.\n",
      "Skipping empty report for 1690_IM-0452-1001-0001.dcm.png: Findings and Impression are empty.\n",
      "Skipping empty report for 1690_IM-0452-1001-0002.dcm.png: Findings and Impression are empty.\n",
      "Skipping empty report for 1761_IM-0497-1001.dcm.png: Findings and Impression are empty.\n",
      "Skipping empty report for 1778_IM-0509-1001.dcm.png: Findings and Impression are empty.\n",
      "Skipping empty report for 1778_IM-0509-2001.dcm.png: Findings and Impression are empty.\n",
      "Skipping empty report for 2115_IM-0744-1001.dcm.png: Findings and Impression are empty.\n",
      "Skipping empty report for 2115_IM-0744-2001.dcm.png: Findings and Impression are empty.\n",
      "Skipping empty report for 2601_IM-1092-4001.dcm.png: Findings and Impression are empty.\n",
      "Skipping empty report for 2697_IM-1167-1001.dcm.png: Findings and Impression are empty.\n",
      "Skipping empty report for 2765_IM-1210-1001.dcm.png: Findings and Impression are empty.\n",
      "Skipping empty report for 2765_IM-1210-2001.dcm.png: Findings and Impression are empty.\n",
      "Skipping empty report for 2881_IM-1285-4004.dcm.png: Findings and Impression are empty.\n",
      "Skipping empty report for 3367_IM-1619-3001.dcm.png: Findings and Impression are empty.\n",
      "Skipping empty report for 3367_IM-1619-4001.dcm.png: Findings and Impression are empty.\n",
      "Skipping empty report for 3376_IM-1625-0001-0001.dcm.png: Findings and Impression are empty.\n",
      "Skipping empty report for 3376_IM-1625-0001-0002.dcm.png: Findings and Impression are empty.\n",
      "Skipping empty report for 3434_IM-1662-1001.dcm.png: Findings and Impression are empty.\n",
      "Skipping empty report for 3434_IM-1662-2001.dcm.png: Findings and Impression are empty.\n",
      "Skipping empty report for 3782_IM-1898-1001.dcm.png: Findings and Impression are empty.\n",
      "Skipping empty report for 3973_IM-2033-1001.dcm.png: Findings and Impression are empty.\n",
      "Manifest saved to /home/intern08/Documents/X_ray_CoT/dataset/image_report_mapping.jsonl. Total entries: 7426\n",
      "\n",
      "Sample manifest entry:\n",
      "{'image_path': '/home/intern08/Documents/X_ray_CoT/dataset/clahe_images/1_IM-0001-4001.dcm.png', 'report': 'Findings: The cardiac silhouette and mediastinum size are within normal limits. There is no pulmonary edema. There is no focal consolidation. There are no XXXX of a pleural effusion. There is no evidence of pneumothorax.\\nImpression: Normal chest x-XXXX.', 'radgraph': {}}\n",
      "Non-empty reports: 7426/7426\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Define paths\n",
    "clahe_folder = '/home/intern08/Documents/X_ray_CoT/dataset/clahe_images'\n",
    "reports_csv = '/home/intern08/Documents/X_ray_CoT/dataset/indiana_reports.csv'\n",
    "projections_csv = '/home/intern08/Documents/X_ray_CoT/dataset/indiana_projections.csv'\n",
    "output_manifest = '/home/intern08/Documents/X_ray_CoT/dataset/image_report_mapping.jsonl'\n",
    "\n",
    "# Load CSVs\n",
    "reports_df = pd.read_csv(reports_csv)\n",
    "projections_df = pd.read_csv(projections_csv)\n",
    "\n",
    "# Fix column name case and handle NaN\n",
    "reports_df['findings'] = reports_df['findings'].fillna('').astype(str).str.strip()\n",
    "reports_df['impression'] = reports_df['impression'].fillna('').astype(str).str.strip()\n",
    "\n",
    "# Merge CSVs on 'uid'\n",
    "merged_df = projections_df.merge(reports_df, on='uid', how='inner')\n",
    "\n",
    "# Initialize manifest\n",
    "manifest = []\n",
    "\n",
    "# Link CLAHE images to reports\n",
    "for idx, row in merged_df.iterrows():\n",
    "    image_filename = row['filename']\n",
    "    image_path = os.path.join(clahe_folder, image_filename)\n",
    "    \n",
    "    if os.path.exists(image_path):\n",
    "        # Extract Findings and Impression (lowercase column names)\n",
    "        findings = row['findings']\n",
    "        impression = row['impression']\n",
    "        report_text = f\"Findings: {findings}\\nImpression: {impression}\".strip()\n",
    "        \n",
    "        # Only include non-empty reports\n",
    "        if findings or impression:  # At least one field is non-empty\n",
    "            manifest.append({\n",
    "                'image_path': image_path,\n",
    "                'report': report_text,\n",
    "                'radgraph': {}  # Placeholder for Step 4.2.5\n",
    "            })\n",
    "        else:\n",
    "            print(f\"Skipping empty report for {image_filename}: Findings and Impression are empty.\")\n",
    "    else:\n",
    "        print(f\"Warning: Image not found: {image_path}\")\n",
    "\n",
    "# Save manifest as JSONL\n",
    "with open(output_manifest, 'w') as f:\n",
    "    for entry in manifest:\n",
    "        f.write(json.dumps(entry) + '\\n')\n",
    "\n",
    "print(f\"Manifest saved to {output_manifest}. Total entries: {len(manifest)}\")\n",
    "\n",
    "# Verify a sample entry\n",
    "if manifest:\n",
    "    print(\"\\nSample manifest entry:\")\n",
    "    print(manifest[0])\n",
    "else:\n",
    "    print(\"No entries created. Check image paths or CSV data.\")\n",
    "\n",
    "# Count non-empty reports\n",
    "non_empty_reports = sum(1 for entry in manifest if entry['report'].strip() != 'Findings: \\nImpression:')\n",
    "print(f\"Non-empty reports: {non_empty_reports}/{len(manifest)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f277f77f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLAHE images missing in projections: set()\n",
      "Projections files missing in CLAHE: {'2560_IM-1064-4001.dcm.png', '2084_IM-0715-1001-0002.dcm.png', '3809_IM-1919-1003002.dcm.png', '2084_IM-0715-2001-0001.dcm.png'}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "clahe_files = set(os.listdir('/home/intern08/Documents/X_ray_CoT/dataset/clahe_images'))\n",
    "projection_files = set(projections_df['filename'])\n",
    "print(f\"CLAHE images missing in projections: {projection_files - clahe_files}\")\n",
    "print(f\"Projections files missing in CLAHE: {clahe_files - projection_files}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5636d1f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   uid                   filename  \\\n",
      "0    1     1_IM-0001-4001.dcm.png   \n",
      "1    1     1_IM-0001-3001.dcm.png   \n",
      "2    2     2_IM-0652-1001.dcm.png   \n",
      "3    2     2_IM-0652-2001.dcm.png   \n",
      "4    3     3_IM-1384-1001.dcm.png   \n",
      "5    3     3_IM-1384-2001.dcm.png   \n",
      "6    4     4_IM-2050-1001.dcm.png   \n",
      "7    4     4_IM-2050-2001.dcm.png   \n",
      "8    5  5_IM-2117-1003002.dcm.png   \n",
      "9    5  5_IM-2117-1004003.dcm.png   \n",
      "\n",
      "                                            findings  \\\n",
      "0  The cardiac silhouette and mediastinum size ar...   \n",
      "1  The cardiac silhouette and mediastinum size ar...   \n",
      "2  Borderline cardiomegaly. Midline sternotomy XX...   \n",
      "3  Borderline cardiomegaly. Midline sternotomy XX...   \n",
      "4                                                      \n",
      "5                                                      \n",
      "6  There are diffuse bilateral interstitial and a...   \n",
      "7  There are diffuse bilateral interstitial and a...   \n",
      "8  The cardiomediastinal silhouette and pulmonary...   \n",
      "9  The cardiomediastinal silhouette and pulmonary...   \n",
      "\n",
      "                                          impression  \n",
      "0                               Normal chest x-XXXX.  \n",
      "1                               Normal chest x-XXXX.  \n",
      "2                       No acute pulmonary findings.  \n",
      "3                       No acute pulmonary findings.  \n",
      "4  No displaced rib fractures, pneumothorax, or p...  \n",
      "5  No displaced rib fractures, pneumothorax, or p...  \n",
      "6  1. Bullous emphysema and interstitial fibrosis...  \n",
      "7  1. Bullous emphysema and interstitial fibrosis...  \n",
      "8              No acute cardiopulmonary abnormality.  \n",
      "9              No acute cardiopulmonary abnormality.  \n",
      "Findings length stats: count    7466.000000\n",
      "mean      189.610903\n",
      "std       117.406713\n",
      "min         0.000000\n",
      "25%       120.000000\n",
      "50%       187.000000\n",
      "75%       254.000000\n",
      "max      1054.000000\n",
      "Name: findings, dtype: float64\n",
      "Impression length stats: count    7466.000000\n",
      "mean       76.233458\n",
      "std        82.561927\n",
      "min         0.000000\n",
      "25%        33.000000\n",
      "50%        39.000000\n",
      "75%        89.000000\n",
      "max       887.000000\n",
      "Name: impression, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(merged_df[['uid', 'filename', 'findings', 'impression']].head(10))\n",
    "print(\"Findings length stats:\", merged_df['findings'].str.len().describe())\n",
    "print(\"Impression length stats:\", merged_df['impression'].str.len().describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f520b80a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reports with both fields empty: 40\n"
     ]
    }
   ],
   "source": [
    "empty_both = merged_df[(merged_df['findings'] == '') & (merged_df['impression'] == '')]\n",
    "print(f\"Reports with both fields empty: {len(empty_both)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb6f17b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2560_IM-1064-4001.dcm.png in original folder: False\n",
      "2084_IM-0715-1001-0002.dcm.png in original folder: False\n",
      "3809_IM-1919-1003002.dcm.png in original folder: False\n",
      "2084_IM-0715-2001-0001.dcm.png in original folder: False\n"
     ]
    }
   ],
   "source": [
    "original_folder = '/kaggle/input/chest-xrays-indiana-university/images/images_normalized'\n",
    "missing_files = ['2560_IM-1064-4001.dcm.png', '2084_IM-0715-1001-0002.dcm.png', '3809_IM-1919-1003002.dcm.png', '2084_IM-0715-2001-0001.dcm.png']\n",
    "for f in missing_files:\n",
    "    print(f\"{f} in original folder: {os.path.exists(os.path.join(original_folder, f))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "289ea8a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2560_IM-1064-4001.dcm.png not found in original folder\n",
      "2084_IM-0715-1001-0002.dcm.png not found in original folder\n",
      "3809_IM-1919-1003002.dcm.png not found in original folder\n",
      "2084_IM-0715-2001-0001.dcm.png not found in original folder\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "clahe_folder = '/home/intern08/Documents/X_ray_CoT/dataset/clahe_images'\n",
    "os.makedirs(clahe_folder, exist_ok=True)\n",
    "for f in missing_files:\n",
    "    input_path = os.path.join(original_folder, f)\n",
    "    output_path = os.path.join(clahe_folder, f)\n",
    "    if os.path.exists(input_path):\n",
    "        img = cv2.imread(input_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if img is not None:\n",
    "            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "            clahe_img = clahe.apply(img)\n",
    "            cv2.imwrite(output_path, clahe_img)\n",
    "            print(f\"Processed {f}\")\n",
    "        else:\n",
    "            print(f\"Failed to load {f}\")\n",
    "    else:\n",
    "        print(f\"{f} not found in original folder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d13bf1e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping empty report for 16_IM-0389-1001.dcm.png: Findings and Impression are empty.\n",
      "Skipping empty report for 16_IM-0389-2001.dcm.png: Findings and Impression are empty.\n",
      "Skipping empty report for 614_IM-2200-4001.dcm.png: Findings and Impression are empty.\n",
      "Skipping empty report for 614_IM-2200-1001.dcm.png: Findings and Impression are empty.\n",
      "Skipping empty report for 673_IM-2247-3001.dcm.png: Findings and Impression are empty.\n",
      "Skipping empty report for 894_IM-2404-0001-0001.dcm.png: Findings and Impression are empty.\n",
      "Skipping empty report for 894_IM-2404-0001-0002.dcm.png: Findings and Impression are empty.\n",
      "Skipping empty report for 1137_IM-0093-12012.dcm.png: Findings and Impression are empty.\n",
      "Skipping empty report for 1137_IM-0093-4004.dcm.png: Findings and Impression are empty.\n",
      "Skipping empty report for 1142_IM-0096-1001.dcm.png: Findings and Impression are empty.\n",
      "Skipping empty report for 1142_IM-0096-2001.dcm.png: Findings and Impression are empty.\n",
      "Skipping empty report for 1147_IM-0099-4004.dcm.png: Findings and Impression are empty.\n",
      "Skipping empty report for 1293_IM-0192-4004.dcm.png: Findings and Impression are empty.\n",
      "Skipping empty report for 1297_IM-0195-4004.dcm.png: Findings and Impression are empty.\n",
      "Skipping empty report for 1297_IM-0195-1001.dcm.png: Findings and Impression are empty.\n",
      "Skipping empty report for 1536_IM-0347-0001-0001.dcm.png: Findings and Impression are empty.\n",
      "Skipping empty report for 1536_IM-0347-0001-0002.dcm.png: Findings and Impression are empty.\n",
      "Skipping empty report for 1536_IM-0347-0001-0003.dcm.png: Findings and Impression are empty.\n",
      "Skipping empty report for 1566_IM-0369-1001.dcm.png: Findings and Impression are empty.\n",
      "Skipping empty report for 1615_IM-0398-4004.dcm.png: Findings and Impression are empty.\n",
      "Skipping empty report for 1690_IM-0452-1001-0001.dcm.png: Findings and Impression are empty.\n",
      "Skipping empty report for 1690_IM-0452-1001-0002.dcm.png: Findings and Impression are empty.\n",
      "Skipping empty report for 1761_IM-0497-1001.dcm.png: Findings and Impression are empty.\n",
      "Skipping empty report for 1778_IM-0509-1001.dcm.png: Findings and Impression are empty.\n",
      "Skipping empty report for 1778_IM-0509-2001.dcm.png: Findings and Impression are empty.\n",
      "Skipping empty report for 2115_IM-0744-1001.dcm.png: Findings and Impression are empty.\n",
      "Skipping empty report for 2115_IM-0744-2001.dcm.png: Findings and Impression are empty.\n",
      "Skipping empty report for 2601_IM-1092-4001.dcm.png: Findings and Impression are empty.\n",
      "Skipping empty report for 2697_IM-1167-1001.dcm.png: Findings and Impression are empty.\n",
      "Skipping empty report for 2765_IM-1210-1001.dcm.png: Findings and Impression are empty.\n",
      "Skipping empty report for 2765_IM-1210-2001.dcm.png: Findings and Impression are empty.\n",
      "Skipping empty report for 2881_IM-1285-4004.dcm.png: Findings and Impression are empty.\n",
      "Skipping empty report for 3367_IM-1619-3001.dcm.png: Findings and Impression are empty.\n",
      "Skipping empty report for 3367_IM-1619-4001.dcm.png: Findings and Impression are empty.\n",
      "Skipping empty report for 3376_IM-1625-0001-0001.dcm.png: Findings and Impression are empty.\n",
      "Skipping empty report for 3376_IM-1625-0001-0002.dcm.png: Findings and Impression are empty.\n",
      "Skipping empty report for 3434_IM-1662-1001.dcm.png: Findings and Impression are empty.\n",
      "Skipping empty report for 3434_IM-1662-2001.dcm.png: Findings and Impression are empty.\n",
      "Skipping empty report for 3782_IM-1898-1001.dcm.png: Findings and Impression are empty.\n",
      "Skipping empty report for 3973_IM-2033-1001.dcm.png: Findings and Impression are empty.\n",
      "Manifest saved to /home/intern08/Documents/X_ray_CoT/dataset/image_report_mapping.jsonl. Total entries: 7426\n",
      "\n",
      "Sample manifest entry:\n",
      "{'image_path': '/home/intern08/Documents/X_ray_CoT/dataset/clahe_images/1_IM-0001-4001.dcm.png', 'report': 'Findings: The cardiac silhouette and mediastinum size are within normal limits. There is no pulmonary edema. There is no focal consolidation. There are no XXXX of a pleural effusion. There is no evidence of pneumothorax.\\nImpression: Normal chest x-XXXX.', 'radgraph': {}}\n",
      "Non-empty reports: 7426/7426\n",
      "3809_IM-1919-1003002.dcm.png in CLAHE folder: True\n",
      "2084_IM-0715-1001-0002.dcm.png in CLAHE folder: True\n",
      "2560_IM-1064-4001.dcm.png in CLAHE folder: True\n",
      "2084_IM-0715-2001-0001.dcm.png in CLAHE folder: True\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Define paths\n",
    "clahe_folder = '/home/intern08/Documents/X_ray_CoT/dataset/clahe_images'\n",
    "reports_csv = '/home/intern08/Documents/X_ray_CoT/dataset/indiana_reports.csv'\n",
    "projections_csv = '/home/intern08/Documents/X_ray_CoT/dataset/indiana_projections.csv'\n",
    "output_manifest = '/home/intern08/Documents/X_ray_CoT/dataset/image_report_mapping.jsonl'\n",
    "\n",
    "# Load CSVs\n",
    "reports_df = pd.read_csv(reports_csv)\n",
    "projections_df = pd.read_csv(projections_csv)\n",
    "\n",
    "# Fix column name case and handle NaN\n",
    "reports_df['findings'] = reports_df['findings'].fillna('').astype(str).str.strip()\n",
    "reports_df['impression'] = reports_df['impression'].fillna('').astype(str).str.strip()\n",
    "\n",
    "# Merge CSVs on 'uid'\n",
    "merged_df = projections_df.merge(reports_df, on='uid', how='inner')\n",
    "\n",
    "# Initialize manifest\n",
    "manifest = []\n",
    "\n",
    "# Link CLAHE images to reports\n",
    "for idx, row in merged_df.iterrows():\n",
    "    image_filename = row['filename']\n",
    "    image_path = os.path.join(clahe_folder, image_filename)\n",
    "    \n",
    "    if os.path.exists(image_path):\n",
    "        # Extract Findings and Impression\n",
    "        findings = row['findings']\n",
    "        impression = row['impression']\n",
    "        report_text = f\"Findings: {findings}\\nImpression: {impression}\".strip()\n",
    "        \n",
    "        # Only include non-empty reports\n",
    "        if findings or impression:\n",
    "            manifest.append({\n",
    "                'image_path': image_path,\n",
    "                'report': report_text,\n",
    "                'radgraph': {}  # Placeholder for Step 4.2.5\n",
    "            })\n",
    "        else:\n",
    "            print(f\"Skipping empty report for {image_filename}: Findings and Impression are empty.\")\n",
    "    else:\n",
    "        print(f\"Warning: Image not found: {image_path}\")\n",
    "\n",
    "# Save manifest as JSONL\n",
    "with open(output_manifest, 'w') as f:\n",
    "    for entry in manifest:\n",
    "        f.write(json.dumps(entry) + '\\n')\n",
    "\n",
    "print(f\"Manifest saved to {output_manifest}. Total entries: {len(manifest)}\")\n",
    "\n",
    "# Verify a sample entry\n",
    "if manifest:\n",
    "    print(\"\\nSample manifest entry:\")\n",
    "    print(manifest[0])\n",
    "else:\n",
    "    print(\"No entries created. Check image paths or CSV data.\")\n",
    "\n",
    "# Count non-empty reports\n",
    "non_empty_reports = sum(1 for entry in manifest if entry['report'].strip() != 'Findings: \\nImpression:')\n",
    "print(f\"Non-empty reports: {non_empty_reports}/{len(manifest)}\")\n",
    "\n",
    "# Verify missing images\n",
    "missing_files = ['3809_IM-1919-1003002.dcm.png', '2084_IM-0715-1001-0002.dcm.png', '2560_IM-1064-4001.dcm.png', '2084_IM-0715-2001-0001.dcm.png']\n",
    "for f in missing_files:\n",
    "    print(f\"{f} in CLAHE folder: {os.path.exists(os.path.join(clahe_folder, f))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ef399d",
   "metadata": {},
   "source": [
    "# 4.3  Data Split Strategy\n",
    "## Use patient‑level stratified split (70/10/20). Verify no leakage via hashed MRN IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8ddea2b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading manifest...\n",
      "Total entries in manifest: 7426\n",
      "Extracting patient IDs...\n",
      "Number of unique patients: 3826\n",
      "Images per patient - Min: 1, Max: 5, Mean: 1.94\n",
      "\n",
      "Patient distribution by number of images:\n",
      "num_images\n",
      "1     435\n",
      "2    3197\n",
      "3     180\n",
      "4      13\n",
      "5       1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Performing stratified patient-level split (70/10/20)...\n",
      "Stratification groups:\n",
      "strata\n",
      "few       3377\n",
      "single     435\n",
      "many        14\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Split sizes:\n",
      "Train patients: 2678 (70.0%)\n",
      "Validation patients: 382 (10.0%)\n",
      "Test patients: 766 (20.0%)\n",
      "✓ No patient leakage detected\n",
      "\n",
      "Image-level split sizes:\n",
      "Train images: 5195\n",
      "Validation images: 739\n",
      "Test images: 1492\n",
      "Saved 5195 entries to /home/intern08/Documents/X_ray_CoT/dataset/data_split/train.jsonl\n",
      "Saved 739 entries to /home/intern08/Documents/X_ray_CoT/dataset/data_split/val.jsonl\n",
      "Saved 1492 entries to /home/intern08/Documents/X_ray_CoT/dataset/data_split/test.jsonl\n",
      "\n",
      "✓ Split summary saved to /home/intern08/Documents/X_ray_CoT/dataset/data_split/split_summary.json\n",
      "\n",
      "=== FINAL SPLIT STATISTICS ===\n",
      "TRAIN:\n",
      "  Patients: 2678 (70.0%)\n",
      "  Images: 5195 (70.0%)\n",
      "  Stratification: Single=304, Few=2364, Many=10\n",
      "VAL:\n",
      "  Patients: 382 (10.0%)\n",
      "  Images: 739 (10.0%)\n",
      "  Stratification: Single=44, Few=337, Many=1\n",
      "TEST:\n",
      "  Patients: 766 (20.0%)\n",
      "  Images: 1492 (20.1%)\n",
      "  Stratification: Single=87, Few=676, Many=3\n",
      "\n",
      "✓ Data splitting completed successfully!\n",
      "Files created in /home/intern08/Documents/X_ray_CoT/dataset/data_split:\n",
      "  - train.jsonl\n",
      "  - val.jsonl\n",
      "  - test.jsonl\n",
      "  - split_summary.json\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import hashlib\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import defaultdict\n",
    "import os\n",
    "\n",
    "# Define paths\n",
    "manifest_file = '/home/intern08/Documents/X_ray_CoT/dataset/image_report_mapping.jsonl'\n",
    "output_dir = '/home/intern08/Documents/X_ray_CoT/dataset/data_split'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Load the manifest\n",
    "print(\"Loading manifest...\")\n",
    "manifest = []\n",
    "with open(manifest_file, 'r') as f:\n",
    "    for line in f:\n",
    "        manifest.append(json.loads(line))\n",
    "\n",
    "print(f\"Total entries in manifest: {len(manifest)}\")\n",
    "\n",
    "# Extract patient IDs from filenames \n",
    "# Indiana University dataset format: {patient_id}_{image_id}.dcm.png\n",
    "print(\"Extracting patient IDs...\")\n",
    "patient_data = defaultdict(list)\n",
    "\n",
    "for entry in manifest:\n",
    "    # Extract filename from path\n",
    "    filename = os.path.basename(entry['image_path'])\n",
    "    \n",
    "    # Extract patient ID (part before first underscore)\n",
    "    patient_id = filename.split('_')[0]\n",
    "    \n",
    "    # Add entry with patient ID\n",
    "    entry['patient_id'] = patient_id\n",
    "    patient_data[patient_id].append(entry)\n",
    "\n",
    "print(f\"Number of unique patients: {len(patient_data)}\")\n",
    "print(f\"Images per patient - Min: {min(len(imgs) for imgs in patient_data.values())}, \"\n",
    "      f\"Max: {max(len(imgs) for imgs in patient_data.values())}, \"\n",
    "      f\"Mean: {np.mean([len(imgs) for imgs in patient_data.values()]):.2f}\")\n",
    "\n",
    "# Create patient-level dataset for stratification\n",
    "patients_list = []\n",
    "for patient_id, entries in patient_data.items():\n",
    "    # Create a hash of patient ID for reproducible splits\n",
    "    patient_hash = hashlib.md5(patient_id.encode()).hexdigest()\n",
    "    \n",
    "    patients_list.append({\n",
    "        'patient_id': patient_id,\n",
    "        'patient_hash': patient_hash,\n",
    "        'num_images': len(entries),\n",
    "        'entries': entries\n",
    "    })\n",
    "\n",
    "# Convert to DataFrame for easier manipulation\n",
    "patients_df = pd.DataFrame([{\n",
    "    'patient_id': p['patient_id'],\n",
    "    'patient_hash': p['patient_hash'],\n",
    "    'num_images': p['num_images']\n",
    "} for p in patients_list])\n",
    "\n",
    "print(\"\\nPatient distribution by number of images:\")\n",
    "print(patients_df['num_images'].value_counts().sort_index())\n",
    "\n",
    "# Stratified split based on number of images per patient\n",
    "# This ensures similar distribution of single vs multi-image patients across splits\n",
    "print(\"\\nPerforming stratified patient-level split (70/10/20)...\")\n",
    "\n",
    "# Create stratification groups based on number of images\n",
    "def create_strata(num_images):\n",
    "    if num_images == 1:\n",
    "        return 'single'\n",
    "    elif num_images <= 3:\n",
    "        return 'few'\n",
    "    else:\n",
    "        return 'many'\n",
    "\n",
    "patients_df['strata'] = patients_df['num_images'].apply(create_strata)\n",
    "print(\"Stratification groups:\")\n",
    "print(patients_df['strata'].value_counts())\n",
    "\n",
    "# First split: 70% train, 30% temp (which will be split into 10% val, 20% test)\n",
    "train_patients, temp_patients = train_test_split(\n",
    "    patients_df, \n",
    "    test_size=0.3, \n",
    "    stratify=patients_df['strata'],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Second split: Split the 30% into 10% val and 20% test\n",
    "# This means 10/30 = 0.333 for validation from the temp set\n",
    "val_patients, test_patients = train_test_split(\n",
    "    temp_patients,\n",
    "    test_size=0.667,  # 20/30 = 0.667 for test\n",
    "    stratify=temp_patients['strata'],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"\\nSplit sizes:\")\n",
    "print(f\"Train patients: {len(train_patients)} ({len(train_patients)/len(patients_df)*100:.1f}%)\")\n",
    "print(f\"Validation patients: {len(val_patients)} ({len(val_patients)/len(patients_df)*100:.1f}%)\")\n",
    "print(f\"Test patients: {len(test_patients)} ({len(test_patients)/len(patients_df)*100:.1f}%)\")\n",
    "\n",
    "# Verify no patient leakage\n",
    "train_ids = set(train_patients['patient_id'])\n",
    "val_ids = set(val_patients['patient_id'])\n",
    "test_ids = set(test_patients['patient_id'])\n",
    "\n",
    "assert len(train_ids & val_ids) == 0, \"Patient leakage between train and validation!\"\n",
    "assert len(train_ids & test_ids) == 0, \"Patient leakage between train and test!\"\n",
    "assert len(val_ids & test_ids) == 0, \"Patient leakage between validation and test!\"\n",
    "print(\"✓ No patient leakage detected\")\n",
    "\n",
    "# Create patient ID to split mapping\n",
    "patient_to_split = {}\n",
    "for pid in train_ids:\n",
    "    patient_to_split[pid] = 'train'\n",
    "for pid in val_ids:\n",
    "    patient_to_split[pid] = 'val'\n",
    "for pid in test_ids:\n",
    "    patient_to_split[pid] = 'test'\n",
    "\n",
    "# Assign splits to all entries\n",
    "train_entries = []\n",
    "val_entries = []\n",
    "test_entries = []\n",
    "\n",
    "for entry in manifest:\n",
    "    split = patient_to_split[entry['patient_id']]\n",
    "    if split == 'train':\n",
    "        train_entries.append(entry)\n",
    "    elif split == 'val':\n",
    "        val_entries.append(entry)\n",
    "    else:  # test\n",
    "        test_entries.append(entry)\n",
    "\n",
    "print(f\"\\nImage-level split sizes:\")\n",
    "print(f\"Train images: {len(train_entries)}\")\n",
    "print(f\"Validation images: {len(val_entries)}\")\n",
    "print(f\"Test images: {len(test_entries)}\")\n",
    "\n",
    "# Save splits as JSONL files\n",
    "splits = {\n",
    "    'train': train_entries,\n",
    "    'val': val_entries,\n",
    "    'test': test_entries\n",
    "}\n",
    "\n",
    "for split_name, entries in splits.items():\n",
    "    output_file = os.path.join(output_dir, f'{split_name}.jsonl')\n",
    "    with open(output_file, 'w') as f:\n",
    "        for entry in entries:\n",
    "            f.write(json.dumps(entry) + '\\n')\n",
    "    print(f\"Saved {len(entries)} entries to {output_file}\")\n",
    "\n",
    "# Create a summary file with split statistics\n",
    "summary = {\n",
    "    'total_patients': len(patients_df),\n",
    "    'total_images': len(manifest),\n",
    "    'splits': {\n",
    "        'train': {\n",
    "            'patients': len(train_patients),\n",
    "            'images': len(train_entries),\n",
    "            'percentage': len(train_patients) / len(patients_df) * 100\n",
    "        },\n",
    "        'val': {\n",
    "            'patients': len(val_patients),\n",
    "            'images': len(val_entries),\n",
    "            'percentage': len(val_patients) / len(patients_df) * 100\n",
    "        },\n",
    "        'test': {\n",
    "            'patients': len(test_patients),\n",
    "            'images': len(test_entries),\n",
    "            'percentage': len(test_patients) / len(patients_df) * 100\n",
    "        }\n",
    "    },\n",
    "    'stratification': {\n",
    "        'single_image_patients': int(patients_df[patients_df['strata'] == 'single'].shape[0]),\n",
    "        'few_image_patients': int(patients_df[patients_df['strata'] == 'few'].shape[0]),\n",
    "        'many_image_patients': int(patients_df[patients_df['strata'] == 'many'].shape[0])\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save summary\n",
    "summary_file = os.path.join(output_dir, 'split_summary.json')\n",
    "with open(summary_file, 'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "print(f\"\\n✓ Split summary saved to {summary_file}\")\n",
    "\n",
    "# Display final statistics\n",
    "print(\"\\n=== FINAL SPLIT STATISTICS ===\")\n",
    "for split_name in ['train', 'val', 'test']:\n",
    "    split_patients = len([p for p in patients_df['patient_id'] if patient_to_split[p] == split_name])\n",
    "    split_images = len(splits[split_name])\n",
    "    print(f\"{split_name.upper()}:\")\n",
    "    print(f\"  Patients: {split_patients} ({split_patients/len(patients_df)*100:.1f}%)\")\n",
    "    print(f\"  Images: {split_images} ({split_images/len(manifest)*100:.1f}%)\")\n",
    "    \n",
    "    # Check stratification preservation\n",
    "    split_patient_df = patients_df[patients_df['patient_id'].isin(\n",
    "        [p for p in patients_df['patient_id'] if patient_to_split[p] == split_name]\n",
    "    )]\n",
    "    print(f\"  Stratification: Single={len(split_patient_df[split_patient_df['strata']=='single'])}, \"\n",
    "          f\"Few={len(split_patient_df[split_patient_df['strata']=='few'])}, \"\n",
    "          f\"Many={len(split_patient_df[split_patient_df['strata']=='many'])}\")\n",
    "\n",
    "print(\"\\n✓ Data splitting completed successfully!\")\n",
    "print(f\"Files created in {output_dir}:\")\n",
    "print(\"  - train.jsonl\")\n",
    "print(\"  - val.jsonl\") \n",
    "print(\"  - test.jsonl\")\n",
    "print(\"  - split_summary.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4d3c8c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Using device: cuda\n",
      "INFO:__main__:============================================================\n",
      "INFO:__main__:STARTING BASELINE MODEL TRAINING\n",
      "INFO:__main__:============================================================\n",
      "INFO:__main__:Configuration:\n",
      "INFO:__main__:  Batch size: 8\n",
      "INFO:__main__:  Learning rate: 0.0001\n",
      "INFO:__main__:  Number of epochs: 5\n",
      "INFO:__main__:  Image size: 224\n",
      "INFO:__main__:  Max sequence length: 256\n",
      "INFO:__main__:============================================================\n",
      "INFO:__main__:Building vocabulary...\n",
      "INFO:__main__:Built vocabulary with 2773 words\n",
      "INFO:__main__:Tokenizer saved to /home/intern08/Documents/X_ray_CoT/dataset/tokenizer.json\n",
      "INFO:__main__:Loaded 5195 valid samples from /home/intern08/Documents/X_ray_CoT/dataset/data_split/train.jsonl\n",
      "INFO:__main__:Loaded 739 valid samples from /home/intern08/Documents/X_ray_CoT/dataset/data_split/val.jsonl\n",
      "/home/intern08/miniconda3/envs/venv/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/intern08/miniconda3/envs/venv/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /home/intern08/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
      "100.0%\n",
      "INFO:__main__:Starting training...\n",
      "INFO:__main__:Epoch 0, Batch 0/650, Loss: 8.0559\n",
      "INFO:__main__:Epoch 0, Batch 100/650, Loss: 3.0935\n",
      "INFO:__main__:Epoch 0, Batch 200/650, Loss: 2.6449\n",
      "INFO:__main__:Epoch 0, Batch 300/650, Loss: 3.4785\n",
      "INFO:__main__:Epoch 0, Batch 400/650, Loss: 2.9297\n",
      "INFO:__main__:Epoch 0, Batch 500/650, Loss: 3.5604\n",
      "INFO:__main__:Epoch 0, Batch 600/650, Loss: 3.0966\n",
      "INFO:__main__:Epoch 1/5 completed in 203.50s\n",
      "INFO:__main__:Train Loss: 2.8853, Val Loss: 2.6031\n",
      "INFO:__main__:New best model saved with val_loss: 2.6031\n",
      "INFO:__main__:Sample reports:\n",
      "INFO:__main__:Sample 1:\n",
      "INFO:__main__:  Original: Findings: The cardiomediastinal silhouette and pulmonary vasculature are within normal limits. There...\n",
      "INFO:__main__:  Generated: are over are as are cuffing cartilage indicated. confluent crescentic is well-expanded is inflated a...\n",
      "INFO:__main__:\n",
      "INFO:__main__:Sample 2:\n",
      "INFO:__main__:  Original: Findings: The cardiomediastinal silhouette and pulmonary vasculature are within normal limits. There...\n",
      "INFO:__main__:  Generated: findings: no pneumothorax, pleural effusion, or focal airspace opacities. heart size and pulmonary v...\n",
      "INFO:__main__:\n",
      "INFO:__main__:Sample 3:\n",
      "INFO:__main__:  Original: Findings: Heart size and mediastinal contour are within normal limits. There is no focal airspace co...\n",
      "INFO:__main__:  Generated: findings: impression: clear bilaterally. calcification as compared projects hyperaerated previous/ch...\n",
      "INFO:__main__:\n",
      "INFO:__main__:Epoch 1, Batch 0/650, Loss: 1.9558\n",
      "INFO:__main__:Epoch 1, Batch 100/650, Loss: 2.5849\n",
      "INFO:__main__:Epoch 1, Batch 200/650, Loss: 1.7614\n",
      "INFO:__main__:Epoch 1, Batch 300/650, Loss: 2.0784\n",
      "INFO:__main__:Epoch 1, Batch 400/650, Loss: 2.4239\n",
      "INFO:__main__:Epoch 1, Batch 500/650, Loss: 1.9523\n",
      "INFO:__main__:Epoch 1, Batch 600/650, Loss: 0.9939\n",
      "INFO:__main__:Epoch 2/5 completed in 207.05s\n",
      "INFO:__main__:Train Loss: 1.8089, Val Loss: 2.1966\n",
      "INFO:__main__:New best model saved with val_loss: 2.1966\n",
      "INFO:__main__:Sample reports:\n",
      "INFO:__main__:Sample 1:\n",
      "INFO:__main__:  Original: Findings: The cardiomediastinal silhouette and pulmonary vasculature are within normal limits. There...\n",
      "INFO:__main__:  Generated: findings: impression: xxxx chest 16.2/24.7. heart size and pulmonary vasculature are within normal l...\n",
      "INFO:__main__:\n",
      "INFO:__main__:Sample 2:\n",
      "INFO:__main__:  Original: Findings: The cardiomediastinal silhouette and pulmonary vasculature are within normal limits. There...\n",
      "INFO:__main__:  Generated: findings: the lungs are clear. the cardiomediastinal silhouette is normal in size and contour. there...\n",
      "INFO:__main__:\n",
      "INFO:__main__:Sample 3:\n",
      "INFO:__main__:  Original: Findings: Heart size and mediastinal contour are within normal limits. There is no focal airspace co...\n",
      "INFO:__main__:  Generated: findings: there is low recess. moderate cardiomegaly. the mediastinum is basilar opacities. of the i...\n",
      "INFO:__main__:\n",
      "INFO:__main__:Epoch 2, Batch 0/650, Loss: 1.2886\n",
      "INFO:__main__:Epoch 2, Batch 100/650, Loss: 1.5424\n",
      "INFO:__main__:Epoch 2, Batch 200/650, Loss: 0.8950\n",
      "INFO:__main__:Epoch 2, Batch 300/650, Loss: 1.3527\n",
      "INFO:__main__:Epoch 2, Batch 400/650, Loss: 0.9955\n",
      "INFO:__main__:Epoch 2, Batch 500/650, Loss: 1.3752\n",
      "INFO:__main__:Epoch 2, Batch 600/650, Loss: 1.1028\n",
      "INFO:__main__:Epoch 3/5 completed in 206.28s\n",
      "INFO:__main__:Train Loss: 1.3427, Val Loss: 1.9818\n",
      "INFO:__main__:New best model saved with val_loss: 1.9818\n",
      "INFO:__main__:Sample reports:\n",
      "INFO:__main__:Sample 1:\n",
      "INFO:__main__:  Original: Findings: The cardiomediastinal silhouette and pulmonary vasculature are within normal limits. There...\n",
      "INFO:__main__:  Generated: findings: heart size is normal. the lungs are clear. there are no focal air space consolidations. no...\n",
      "INFO:__main__:\n",
      "INFO:__main__:Sample 2:\n",
      "INFO:__main__:  Original: Findings: The cardiomediastinal silhouette and pulmonary vasculature are within normal limits. There...\n",
      "INFO:__main__:  Generated: findings: the heart is mildly enlarged. the pulmonary xxxx is enlarged with surgical basilar atelect...\n",
      "INFO:__main__:\n",
      "INFO:__main__:Sample 3:\n",
      "INFO:__main__:  Original: Findings: Heart size and mediastinal contour are within normal limits. There is no focal airspace co...\n",
      "INFO:__main__:  Generated: findings: impression: enlarged left subclavian central scarring, provide apical pleural effusion. le...\n",
      "INFO:__main__:\n",
      "INFO:__main__:Epoch 3, Batch 0/650, Loss: 1.2776\n",
      "INFO:__main__:Epoch 3, Batch 100/650, Loss: 1.2780\n",
      "INFO:__main__:Epoch 3, Batch 200/650, Loss: 0.8427\n",
      "INFO:__main__:Epoch 3, Batch 300/650, Loss: 0.9672\n",
      "INFO:__main__:Epoch 3, Batch 400/650, Loss: 0.9656\n",
      "INFO:__main__:Epoch 3, Batch 500/650, Loss: 1.3225\n",
      "INFO:__main__:Epoch 3, Batch 600/650, Loss: 0.9058\n",
      "INFO:__main__:Epoch 4/5 completed in 205.31s\n",
      "INFO:__main__:Train Loss: 1.0075, Val Loss: 1.9714\n",
      "INFO:__main__:New best model saved with val_loss: 1.9714\n",
      "INFO:__main__:Sample reports:\n",
      "INFO:__main__:Sample 1:\n",
      "INFO:__main__:  Original: Findings: The cardiomediastinal silhouette and pulmonary vasculature are within normal limits. There...\n",
      "INFO:__main__:  Generated: findings: normal cardiomediastinal contours. no pneumothorax or pleural effusions. left lung xxxx. l...\n",
      "INFO:__main__:\n",
      "INFO:__main__:Sample 2:\n",
      "INFO:__main__:  Original: Findings: The cardiomediastinal silhouette and pulmonary vasculature are within normal limits. There...\n",
      "INFO:__main__:  Generated: findings: chest. stable left midlung overlies the lungs, consistent with superior noncalcified lung,...\n",
      "INFO:__main__:\n",
      "INFO:__main__:Sample 3:\n",
      "INFO:__main__:  Original: Findings: Heart size and mediastinal contour are within normal limits. There is no focal airspace co...\n",
      "INFO:__main__:  Generated: findings: low lung volumes. the trachea is midline. the cardiomediastinal silhouette is normal. pulm...\n",
      "INFO:__main__:\n",
      "INFO:__main__:Epoch 4, Batch 0/650, Loss: 0.8822\n",
      "INFO:__main__:Epoch 4, Batch 100/650, Loss: 1.1219\n",
      "INFO:__main__:Epoch 4, Batch 200/650, Loss: 0.7398\n",
      "INFO:__main__:Epoch 4, Batch 300/650, Loss: 0.8558\n",
      "INFO:__main__:Epoch 4, Batch 400/650, Loss: 0.7225\n",
      "INFO:__main__:Epoch 4, Batch 500/650, Loss: 0.6694\n",
      "INFO:__main__:Epoch 4, Batch 600/650, Loss: 0.4965\n",
      "INFO:__main__:Epoch 5/5 completed in 206.66s\n",
      "INFO:__main__:Train Loss: 0.8133, Val Loss: 1.9717\n",
      "INFO:__main__:Training completed!\n",
      "INFO:__main__:============================================================\n",
      "INFO:__main__:TRAINING COMPLETED SUCCESSFULLY\n",
      "INFO:__main__:============================================================\n",
      "INFO:__main__:Best model saved at: /home/intern08/Documents/X_ray_CoT/dataset/best_model.pth\n",
      "INFO:__main__:Starting evaluation on test set...\n",
      "/tmp/ipykernel_17826/243816458.py:620: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(model_path, map_location=device)\n",
      "INFO:__main__:Loaded 1492 valid samples from /home/intern08/Documents/X_ray_CoT/dataset/data_split/test.jsonl\n",
      "INFO:__main__:Starting evaluation...\n",
      "INFO:__main__:Processed 0 samples\n",
      "INFO:__main__:Processed 80 samples\n",
      "INFO:__main__:Processed 160 samples\n",
      "INFO:__main__:Processed 240 samples\n",
      "INFO:__main__:Processed 320 samples\n",
      "INFO:__main__:Processed 400 samples\n",
      "INFO:__main__:Processed 480 samples\n",
      "INFO:__main__:Processed 560 samples\n",
      "INFO:__main__:Processed 640 samples\n",
      "INFO:__main__:Processed 720 samples\n",
      "INFO:__main__:Processed 800 samples\n",
      "INFO:__main__:Processed 880 samples\n",
      "INFO:__main__:Processed 960 samples\n",
      "INFO:__main__:Processed 1040 samples\n",
      "INFO:__main__:Processed 1120 samples\n",
      "INFO:__main__:Processed 1200 samples\n",
      "INFO:__main__:Processed 1280 samples\n",
      "INFO:__main__:Processed 1360 samples\n",
      "INFO:__main__:Processed 1440 samples\n",
      "INFO:__main__:Evaluation completed!\n",
      "INFO:__main__:Average BLEU-1 Score: 0.3869\n",
      "INFO:__main__:Results saved to /home/intern08/Documents/X_ray_CoT/dataset/evaluation_results.json\n",
      "INFO:__main__:============================================================\n",
      "INFO:__main__:EVALUATION COMPLETED\n",
      "INFO:__main__:============================================================\n",
      "INFO:__main__:Average BLEU-1 Score: 0.3869\n",
      "INFO:__main__:Evaluation results saved to: /home/intern08/Documents/X_ray_CoT/dataset/evaluation_results.json\n",
      "INFO:__main__:\n",
      "Sample Results:\n",
      "INFO:__main__:----------------------------------------\n",
      "INFO:__main__:Sample 1 (BLEU: 0.138):\n",
      "INFO:__main__:  Original: Findings: Borderline cardiomegaly. Midline sternotomy XXXX. Enlarged pulmonary arteries. Clear lungs. Inferior XXXX XXXX XXXX.\n",
      "Impression: No acute pu...\n",
      "INFO:__main__:  Generated: findings: impression: midlung, xxxx opacities in the left midlung. resolution of greater than right. the heart. a combination of airspace disease. no ...\n",
      "INFO:__main__:\n",
      "INFO:__main__:Sample 2 (BLEU: 0.227):\n",
      "INFO:__main__:  Original: Findings: Borderline cardiomegaly. Midline sternotomy XXXX. Enlarged pulmonary arteries. Clear lungs. Inferior XXXX XXXX XXXX.\n",
      "Impression: No acute pu...\n",
      "INFO:__main__:  Generated: findings: no pneumothorax, pleural effusion or airspace consolidation. cardiomediastinal size is within normal limits. pulmonary vasculature is intact...\n",
      "INFO:__main__:\n",
      "INFO:__main__:Sample 3 (BLEU: 0.450):\n",
      "INFO:__main__:  Original: Findings: There are diffuse bilateral interstitial and alveolar opacities consistent with chronic obstructive lung disease and bullous emphysema. Ther...\n",
      "INFO:__main__:  Generated: findings: impression: heart size is top normal. the lungs are clear with no effusions or pneumothorax. case left-sided chest x-xxxx....\n",
      "INFO:__main__:\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Simplified Baseline Model for Radiology Report Generation\n",
    "Compatible with Kaggle environment and existing libraries\n",
    "\n",
    "Architecture:\n",
    "- Vision Encoder: ResNet-50 (pre-trained)\n",
    "- Text Decoder: GPT-2 with custom heads\n",
    "- Simple fusion mechanism\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import json\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "import logging\n",
    "import gc\n",
    "import time\n",
    "from collections import defaultdict\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class ModelConfig:\n",
    "    \"\"\"Configuration for the simplified baseline model\"\"\"\n",
    "    # Model architecture\n",
    "    vision_encoder = \"resnet50\"\n",
    "    vision_hidden_size = 2048\n",
    "    text_hidden_size = 768\n",
    "    vocab_size = 50000\n",
    "    max_length = 256\n",
    "    \n",
    "    # Training configuration\n",
    "    batch_size = 8  # Reduced for memory constraints\n",
    "    learning_rate = 1e-4\n",
    "    weight_decay = 1e-4\n",
    "    num_epochs = 5  # Reduced for faster training\n",
    "    warmup_steps = 100\n",
    "    \n",
    "    # Image processing\n",
    "    image_size = 224\n",
    "    \n",
    "    # Paths\n",
    "    train_file = \"/home/intern08/Documents/X_ray_CoT/dataset/data_split/train.jsonl\"\n",
    "    val_file = \"/home/intern08/Documents/X_ray_CoT/dataset/data_split/val.jsonl\"\n",
    "    test_file = \"/home/intern08/Documents/X_ray_CoT/dataset/data_split/test.jsonl\"\n",
    "    output_dir = \"/home/intern08/Documents/X_ray_CoT/dataset\"\n",
    "\n",
    "class SimpleTokenizer:\n",
    "    \"\"\"Simple tokenizer for radiology reports\"\"\"\n",
    "    \n",
    "    def __init__(self, vocab_size=50000):\n",
    "        self.vocab_size = vocab_size\n",
    "        self.word_to_id = {'<pad>': 0, '<unk>': 1, '<sos>': 2, '<eos>': 3}\n",
    "        self.id_to_word = {0: '<pad>', 1: '<unk>', 2: '<sos>', 3: '<eos>'}\n",
    "        self.next_id = 4\n",
    "        \n",
    "    def build_vocab(self, texts):\n",
    "        \"\"\"Build vocabulary from texts\"\"\"\n",
    "        word_counts = defaultdict(int)\n",
    "        \n",
    "        for text in texts:\n",
    "            words = text.lower().split()\n",
    "            for word in words:\n",
    "                word_counts[word] += 1\n",
    "        \n",
    "        # Add most frequent words to vocabulary\n",
    "        sorted_words = sorted(word_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        for word, count in sorted_words[:self.vocab_size - 4]:\n",
    "            if word not in self.word_to_id:\n",
    "                self.word_to_id[word] = self.next_id\n",
    "                self.id_to_word[self.next_id] = word\n",
    "                self.next_id += 1\n",
    "        \n",
    "        logger.info(f\"Built vocabulary with {len(self.word_to_id)} words\")\n",
    "    \n",
    "    def encode(self, text, max_length=256):\n",
    "        \"\"\"Encode text to token IDs\"\"\"\n",
    "        words = text.lower().split()\n",
    "        tokens = [self.word_to_id.get(word, 1) for word in words]  # 1 is <unk>\n",
    "        \n",
    "        # Add start and end tokens\n",
    "        tokens = [2] + tokens + [3]  # 2 is <sos>, 3 is <eos>\n",
    "        \n",
    "        # Pad or truncate\n",
    "        if len(tokens) > max_length:\n",
    "            tokens = tokens[:max_length]\n",
    "        else:\n",
    "            tokens.extend([0] * (max_length - len(tokens)))  # 0 is <pad>\n",
    "        \n",
    "        return tokens\n",
    "    \n",
    "    def decode(self, token_ids):\n",
    "        \"\"\"Decode token IDs to text\"\"\"\n",
    "        words = []\n",
    "        for token_id in token_ids:\n",
    "            if token_id == 3:  # <eos>\n",
    "                break\n",
    "            if token_id not in [0, 2]:  # Skip <pad> and <sos>\n",
    "                words.append(self.id_to_word.get(token_id, '<unk>'))\n",
    "        \n",
    "        return ' '.join(words)\n",
    "\n",
    "class RadiologyDataset(Dataset):\n",
    "    \"\"\"Simplified dataset class for radiology images and reports\"\"\"\n",
    "    \n",
    "    def __init__(self, jsonl_file: str, tokenizer: SimpleTokenizer, transform=None, max_length=256):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.transform = transform\n",
    "        self.max_length = max_length\n",
    "        \n",
    "        # Load data\n",
    "        self.data = []\n",
    "        with open(jsonl_file, 'r') as f:\n",
    "            for line in f:\n",
    "                entry = json.loads(line)\n",
    "                if os.path.exists(entry['image_path']):  # Only include existing images\n",
    "                    self.data.append(entry)\n",
    "        \n",
    "        logger.info(f\"Loaded {len(self.data)} valid samples from {jsonl_file}\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        entry = self.data[idx]\n",
    "        \n",
    "        # Load image\n",
    "        try:\n",
    "            image = Image.open(entry['image_path']).convert('RGB')\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error loading image {entry['image_path']}: {e}\")\n",
    "            # Create dummy image\n",
    "            image = torch.zeros(3, 224, 224)\n",
    "        \n",
    "        # Tokenize report\n",
    "        report = entry['report']\n",
    "        tokens = self.tokenizer.encode(report, self.max_length)\n",
    "        \n",
    "        return {\n",
    "            'image': image,\n",
    "            'tokens': torch.tensor(tokens, dtype=torch.long),\n",
    "            'report': report,\n",
    "            'patient_id': entry.get('patient_id', 'unknown')\n",
    "        }\n",
    "\n",
    "class VisionEncoder(nn.Module):\n",
    "    \"\"\"Vision encoder using ResNet-50\"\"\"\n",
    "    \n",
    "    def __init__(self, hidden_size=768):\n",
    "        super().__init__()\n",
    "        # Load pre-trained ResNet-50\n",
    "        resnet = models.resnet50(pretrained=True)\n",
    "        \n",
    "        # Remove final classification layer\n",
    "        self.features = nn.Sequential(*list(resnet.children())[:-1])\n",
    "        \n",
    "        # Add projection layer\n",
    "        self.projection = nn.Linear(2048, hidden_size)\n",
    "        \n",
    "        # Freeze initial layers\n",
    "        for param in list(self.features.parameters())[:50]:\n",
    "            param.requires_grad = False\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Extract features\n",
    "        features = self.features(x)  # [batch_size, 2048, 1, 1]\n",
    "        features = features.view(features.size(0), -1)  # [batch_size, 2048]\n",
    "        \n",
    "        # Project to hidden size\n",
    "        features = self.projection(features)  # [batch_size, hidden_size]\n",
    "        \n",
    "        return features\n",
    "\n",
    "class TextDecoder(nn.Module):\n",
    "    \"\"\"Simple text decoder with attention\"\"\"\n",
    "    \n",
    "    def __init__(self, vocab_size, hidden_size=768, num_layers=6):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.vocab_size = vocab_size\n",
    "        \n",
    "        # Embedding layer\n",
    "        self.embedding = nn.Embedding(vocab_size, hidden_size)\n",
    "        \n",
    "        # Transformer decoder layers\n",
    "        decoder_layer = nn.TransformerDecoderLayer(\n",
    "            d_model=hidden_size,\n",
    "            nhead=8,\n",
    "            dim_feedforward=hidden_size * 4,\n",
    "            dropout=0.1,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.transformer_decoder = nn.TransformerDecoder(decoder_layer, num_layers)\n",
    "        \n",
    "        # Output projection\n",
    "        self.output_projection = nn.Linear(hidden_size, vocab_size)\n",
    "        \n",
    "        # Position encoding\n",
    "        self.pos_encoding = self._create_position_encoding(512, hidden_size)\n",
    "    \n",
    "    def _create_position_encoding(self, max_len, hidden_size):\n",
    "        \"\"\"Create positional encoding\"\"\"\n",
    "        pe = torch.zeros(max_len, hidden_size)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        \n",
    "        div_term = torch.exp(torch.arange(0, hidden_size, 2).float() * \n",
    "                           (-np.log(10000.0) / hidden_size))\n",
    "        \n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        \n",
    "        return pe.unsqueeze(0)  # [1, max_len, hidden_size]\n",
    "    \n",
    "    def forward(self, tokens, vision_features, attention_mask=None):\n",
    "        batch_size, seq_len = tokens.shape\n",
    "        \n",
    "        # Embed tokens\n",
    "        token_embeds = self.embedding(tokens)  # [batch_size, seq_len, hidden_size]\n",
    "        \n",
    "        # Add positional encoding\n",
    "        if seq_len <= self.pos_encoding.size(1):\n",
    "            pos_enc = self.pos_encoding[:, :seq_len, :].to(token_embeds.device)\n",
    "            token_embeds = token_embeds + pos_enc\n",
    "        \n",
    "        # Prepare vision features as memory\n",
    "        vision_memory = vision_features.unsqueeze(1)  # [batch_size, 1, hidden_size]\n",
    "        \n",
    "        # Create causal mask for decoder\n",
    "        causal_mask = torch.triu(torch.ones(seq_len, seq_len), diagonal=1).bool()\n",
    "        causal_mask = causal_mask.to(token_embeds.device)\n",
    "        \n",
    "        # Transformer decoder\n",
    "        output = self.transformer_decoder(\n",
    "            tgt=token_embeds,\n",
    "            memory=vision_memory,\n",
    "            tgt_mask=causal_mask\n",
    "        )\n",
    "        \n",
    "        # Project to vocabulary\n",
    "        logits = self.output_projection(output)\n",
    "        \n",
    "        return logits\n",
    "\n",
    "class RadiologyModel(nn.Module):\n",
    "    \"\"\"Complete radiology report generation model\"\"\"\n",
    "    \n",
    "    def __init__(self, vocab_size, hidden_size=768):\n",
    "        super().__init__()\n",
    "        self.vision_encoder = VisionEncoder(hidden_size)\n",
    "        self.text_decoder = TextDecoder(vocab_size, hidden_size)\n",
    "        \n",
    "    def forward(self, images, tokens):\n",
    "        # Encode vision features\n",
    "        vision_features = self.vision_encoder(images)\n",
    "        \n",
    "        # Decode text\n",
    "        logits = self.text_decoder(tokens[:, :-1], vision_features)  # Teacher forcing\n",
    "        \n",
    "        return logits\n",
    "    \n",
    "    def generate(self, images, tokenizer, max_length=128, temperature=1.0):\n",
    "        \"\"\"Generate reports for given images\"\"\"\n",
    "        self.eval()\n",
    "        batch_size = images.size(0)\n",
    "        \n",
    "        # Encode vision features\n",
    "        with torch.no_grad():\n",
    "            vision_features = self.vision_encoder(images)\n",
    "            \n",
    "            # Start with <sos> token\n",
    "            generated = torch.full((batch_size, 1), 2, dtype=torch.long, device=images.device)\n",
    "            \n",
    "            for _ in range(max_length):\n",
    "                # Get logits for current sequence\n",
    "                logits = self.text_decoder(generated, vision_features)\n",
    "                \n",
    "                # Get next token probabilities\n",
    "                next_logits = logits[:, -1, :] / temperature\n",
    "                next_probs = F.softmax(next_logits, dim=-1)\n",
    "                \n",
    "                # Sample next token\n",
    "                next_tokens = torch.multinomial(next_probs, 1)\n",
    "                \n",
    "                # Append to generated sequence\n",
    "                generated = torch.cat([generated, next_tokens], dim=1)\n",
    "                \n",
    "                # Stop if all sequences have generated <eos> token\n",
    "                if (next_tokens == 3).all():  # 3 is <eos>\n",
    "                    break\n",
    "        \n",
    "        return generated\n",
    "\n",
    "class ModelTrainer:\n",
    "    \"\"\"Trainer class for the radiology model\"\"\"\n",
    "    \n",
    "    def __init__(self, config: ModelConfig):\n",
    "        self.config = config\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        logger.info(f\"Using device: {self.device}\")\n",
    "        \n",
    "        # Initialize tokenizer\n",
    "        self.tokenizer = SimpleTokenizer(config.vocab_size)\n",
    "        \n",
    "        # Create transforms\n",
    "        self.train_transform = transforms.Compose([\n",
    "            transforms.Resize((config.image_size, config.image_size)),\n",
    "            transforms.RandomHorizontalFlip(0.5),\n",
    "            transforms.ColorJitter(brightness=0.1, contrast=0.1),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        \n",
    "        self.val_transform = transforms.Compose([\n",
    "            transforms.Resize((config.image_size, config.image_size)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        \n",
    "    def build_tokenizer(self, train_file: str):\n",
    "        \"\"\"Build tokenizer vocabulary from training data\"\"\"\n",
    "        logger.info(\"Building vocabulary...\")\n",
    "        \n",
    "        texts = []\n",
    "        with open(train_file, 'r') as f:\n",
    "            for line in f:\n",
    "                entry = json.loads(line)\n",
    "                texts.append(entry['report'])\n",
    "        \n",
    "        self.tokenizer.build_vocab(texts)\n",
    "        \n",
    "        # Save tokenizer\n",
    "        tokenizer_path = os.path.join(self.config.output_dir, 'tokenizer.json')\n",
    "        os.makedirs(os.path.dirname(tokenizer_path), exist_ok=True)\n",
    "        \n",
    "        tokenizer_data = {\n",
    "            'word_to_id': self.tokenizer.word_to_id,\n",
    "            'id_to_word': self.tokenizer.id_to_word,\n",
    "            'vocab_size': len(self.tokenizer.word_to_id)\n",
    "        }\n",
    "        \n",
    "        with open(tokenizer_path, 'w') as f:\n",
    "            json.dump(tokenizer_data, f, indent=2)\n",
    "        \n",
    "        logger.info(f\"Tokenizer saved to {tokenizer_path}\")\n",
    "    \n",
    "    def create_dataloaders(self):\n",
    "        \"\"\"Create training and validation dataloaders\"\"\"\n",
    "        \n",
    "        train_dataset = RadiologyDataset(\n",
    "            self.config.train_file, self.tokenizer, self.train_transform, self.config.max_length\n",
    "        )\n",
    "        \n",
    "        val_dataset = RadiologyDataset(\n",
    "            self.config.val_file, self.tokenizer, self.val_transform, self.config.max_length\n",
    "        )\n",
    "        \n",
    "        train_dataloader = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=self.config.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=2,\n",
    "            pin_memory=True if torch.cuda.is_available() else False\n",
    "        )\n",
    "        \n",
    "        val_dataloader = DataLoader(\n",
    "            val_dataset,\n",
    "            batch_size=self.config.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=2,\n",
    "            pin_memory=True if torch.cuda.is_available() else False\n",
    "        )\n",
    "        \n",
    "        return train_dataloader, val_dataloader\n",
    "    \n",
    "    def train_epoch(self, model, train_dataloader, optimizer, criterion, epoch):\n",
    "        \"\"\"Train for one epoch\"\"\"\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        num_batches = 0\n",
    "        \n",
    "        for batch_idx, batch in enumerate(train_dataloader):\n",
    "            # Move to device\n",
    "            images = batch['image'].to(self.device)\n",
    "            tokens = batch['tokens'].to(self.device)\n",
    "            \n",
    "            # Forward pass\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(images, tokens)\n",
    "            \n",
    "            # Calculate loss (ignore padding tokens)\n",
    "            targets = tokens[:, 1:]  # Shift targets\n",
    "            logits = logits.reshape(-1, logits.size(-1))\n",
    "            targets = targets.reshape(-1)\n",
    "            \n",
    "            # Create mask to ignore padding tokens\n",
    "            mask = targets != 0  # 0 is <pad> token\n",
    "            \n",
    "            if mask.sum() > 0:  # Only calculate loss if there are non-padding tokens\n",
    "                loss = criterion(logits[mask], targets[mask])\n",
    "                \n",
    "                # Backward pass\n",
    "                loss.backward()\n",
    "                \n",
    "                # Gradient clipping\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "                \n",
    "                optimizer.step()\n",
    "                \n",
    "                total_loss += loss.item()\n",
    "                num_batches += 1\n",
    "            \n",
    "            # Log progress\n",
    "            if batch_idx % 100 == 0:\n",
    "                logger.info(f\"Epoch {epoch}, Batch {batch_idx}/{len(train_dataloader)}, \"\n",
    "                          f\"Loss: {loss.item():.4f}\")\n",
    "            \n",
    "            # Memory cleanup\n",
    "            if batch_idx % 50 == 0:\n",
    "                gc.collect()\n",
    "                if torch.cuda.is_available():\n",
    "                    torch.cuda.empty_cache()\n",
    "        \n",
    "        return total_loss / max(num_batches, 1)\n",
    "    \n",
    "    def validate_epoch(self, model, val_dataloader, criterion):\n",
    "        \"\"\"Validate for one epoch\"\"\"\n",
    "        model.eval()\n",
    "        total_loss = 0\n",
    "        num_batches = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in val_dataloader:\n",
    "                images = batch['image'].to(self.device)\n",
    "                tokens = batch['tokens'].to(self.device)\n",
    "                \n",
    "                # Forward pass\n",
    "                logits = model(images, tokens)\n",
    "                \n",
    "                # Calculate loss\n",
    "                targets = tokens[:, 1:]\n",
    "                logits = logits.reshape(-1, logits.size(-1))\n",
    "                targets = targets.reshape(-1)\n",
    "                \n",
    "                # Create mask to ignore padding tokens\n",
    "                mask = targets != 0\n",
    "                \n",
    "                if mask.sum() > 0:\n",
    "                    loss = criterion(logits[mask], targets[mask])\n",
    "                    total_loss += loss.item()\n",
    "                    num_batches += 1\n",
    "        \n",
    "        return total_loss / max(num_batches, 1)\n",
    "    \n",
    "    def generate_sample_reports(self, model, val_dataloader, num_samples=5):\n",
    "        \"\"\"Generate sample reports for evaluation\"\"\"\n",
    "        model.eval()\n",
    "        samples = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch_idx, batch in enumerate(val_dataloader):\n",
    "                if len(samples) >= num_samples:\n",
    "                    break\n",
    "                \n",
    "                images = batch['image'].to(self.device)\n",
    "                original_reports = batch['report']\n",
    "                patient_ids = batch['patient_id']\n",
    "                \n",
    "                # Generate reports\n",
    "                generated_tokens = model.generate(images, self.tokenizer, max_length=64)\n",
    "                \n",
    "                for i in range(min(len(images), num_samples - len(samples))):\n",
    "                    generated_text = self.tokenizer.decode(generated_tokens[i].cpu().tolist())\n",
    "                    \n",
    "                    samples.append({\n",
    "                        'patient_id': patient_ids[i],\n",
    "                        'original': original_reports[i],\n",
    "                        'generated': generated_text\n",
    "                    })\n",
    "        \n",
    "        return samples\n",
    "    \n",
    "    def train(self):\n",
    "        \"\"\"Complete training pipeline\"\"\"\n",
    "        \n",
    "        # Create output directory\n",
    "        os.makedirs(self.config.output_dir, exist_ok=True)\n",
    "        \n",
    "        # Build tokenizer\n",
    "        self.build_tokenizer(self.config.train_file)\n",
    "        \n",
    "        # Create dataloaders\n",
    "        train_dataloader, val_dataloader = self.create_dataloaders()\n",
    "        \n",
    "        # Initialize model\n",
    "        vocab_size = len(self.tokenizer.word_to_id)\n",
    "        model = RadiologyModel(vocab_size, self.config.text_hidden_size)\n",
    "        model.to(self.device)\n",
    "        \n",
    "        # Loss function and optimizer\n",
    "        criterion = nn.CrossEntropyLoss(ignore_index=0)  # Ignore padding tokens\n",
    "        optimizer = torch.optim.AdamW(\n",
    "            model.parameters(),\n",
    "            lr=self.config.learning_rate,\n",
    "            weight_decay=self.config.weight_decay\n",
    "        )\n",
    "        \n",
    "        # Learning rate scheduler\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "            optimizer, T_max=self.config.num_epochs\n",
    "        )\n",
    "        \n",
    "        # Training loop\n",
    "        best_val_loss = float('inf')\n",
    "        patience_counter = 0\n",
    "        patience = 3\n",
    "        \n",
    "        logger.info(\"Starting training...\")\n",
    "        \n",
    "        for epoch in range(self.config.num_epochs):\n",
    "            start_time = time.time()\n",
    "            \n",
    "            # Train\n",
    "            train_loss = self.train_epoch(model, train_dataloader, optimizer, criterion, epoch)\n",
    "            \n",
    "            # Validate\n",
    "            val_loss = self.validate_epoch(model, val_dataloader, criterion)\n",
    "            \n",
    "            # Update scheduler\n",
    "            scheduler.step()\n",
    "            \n",
    "            epoch_time = time.time() - start_time\n",
    "            \n",
    "            logger.info(f\"Epoch {epoch+1}/{self.config.num_epochs} completed in {epoch_time:.2f}s\")\n",
    "            logger.info(f\"Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "            \n",
    "            # Save best model\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                patience_counter = 0\n",
    "                \n",
    "                # Save model\n",
    "                model_path = os.path.join(self.config.output_dir, 'best_model.pth')\n",
    "                torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'train_loss': train_loss,\n",
    "                    'val_loss': val_loss,\n",
    "                    'config': self.config\n",
    "                }, model_path)\n",
    "                \n",
    "                logger.info(f\"New best model saved with val_loss: {val_loss:.4f}\")\n",
    "                \n",
    "                # Generate sample reports\n",
    "                samples = self.generate_sample_reports(model, val_dataloader)\n",
    "                \n",
    "                # Save samples\n",
    "                samples_path = os.path.join(self.config.output_dir, f'samples_epoch_{epoch+1}.json')\n",
    "                with open(samples_path, 'w') as f:\n",
    "                    json.dump(samples, f, indent=2)\n",
    "                \n",
    "                logger.info(\"Sample reports:\")\n",
    "                for i, sample in enumerate(samples[:3]):\n",
    "                    logger.info(f\"Sample {i+1}:\")\n",
    "                    logger.info(f\"  Original: {sample['original'][:100]}...\")\n",
    "                    logger.info(f\"  Generated: {sample['generated'][:100]}...\")\n",
    "                    logger.info(\"\")\n",
    "            \n",
    "            else:\n",
    "                patience_counter += 1\n",
    "            \n",
    "            # Early stopping\n",
    "            if patience_counter >= patience:\n",
    "                logger.info(f\"Early stopping at epoch {epoch+1}\")\n",
    "                break\n",
    "        \n",
    "        logger.info(\"Training completed!\")\n",
    "        return os.path.join(self.config.output_dir, 'best_model.pth')\n",
    "\n",
    "# Evaluation functions\n",
    "def calculate_bleu_score(reference, hypothesis):\n",
    "    \"\"\"Simple BLEU-1 score calculation\"\"\"\n",
    "    ref_words = set(reference.lower().split())\n",
    "    hyp_words = set(hypothesis.lower().split())\n",
    "    \n",
    "    if len(hyp_words) == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    overlap = len(ref_words.intersection(hyp_words))\n",
    "    return overlap / len(hyp_words)\n",
    "\n",
    "def evaluate_model(model_path: str, test_file: str, tokenizer_path: str, config: ModelConfig):\n",
    "    \"\"\"Evaluate the trained model\"\"\"\n",
    "    \n",
    "    # Load tokenizer\n",
    "    with open(tokenizer_path, 'r') as f:\n",
    "        tokenizer_data = json.load(f)\n",
    "    \n",
    "    tokenizer = SimpleTokenizer()\n",
    "    tokenizer.word_to_id = tokenizer_data['word_to_id']\n",
    "    tokenizer.id_to_word = {int(k): v for k, v in tokenizer_data['id_to_word'].items()}\n",
    "    \n",
    "    # Load model\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    vocab_size = len(tokenizer.word_to_id)\n",
    "    model = RadiologyModel(vocab_size, config.text_hidden_size)\n",
    "    \n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    # Create test dataset\n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.Resize((config.image_size, config.image_size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    test_dataset = RadiologyDataset(test_file, tokenizer, val_transform, config.max_length)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=config.batch_size, shuffle=False)\n",
    "    \n",
    "    # Evaluate\n",
    "    bleu_scores = []\n",
    "    all_results = []\n",
    "    \n",
    "    logger.info(\"Starting evaluation...\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(test_dataloader):\n",
    "            images = batch['image'].to(device)\n",
    "            original_reports = batch['report']\n",
    "            patient_ids = batch['patient_id']\n",
    "            \n",
    "            # Generate reports\n",
    "            generated_tokens = model.generate(images, tokenizer, max_length=128)\n",
    "            \n",
    "            for i in range(len(images)):\n",
    "                generated_text = tokenizer.decode(generated_tokens[i].cpu().tolist())\n",
    "                original_text = original_reports[i]\n",
    "                \n",
    "                # Calculate BLEU score\n",
    "                bleu = calculate_bleu_score(original_text, generated_text)\n",
    "                bleu_scores.append(bleu)\n",
    "                \n",
    "                all_results.append({\n",
    "                    'patient_id': patient_ids[i],\n",
    "                    'original': original_text,\n",
    "                    'generated': generated_text,\n",
    "                    'bleu_score': bleu\n",
    "                })\n",
    "            \n",
    "            if batch_idx % 10 == 0:\n",
    "                logger.info(f\"Processed {batch_idx * config.batch_size} samples\")\n",
    "    \n",
    "    # Calculate metrics\n",
    "    avg_bleu = np.mean(bleu_scores)\n",
    "    \n",
    "    logger.info(f\"Evaluation completed!\")\n",
    "    logger.info(f\"Average BLEU-1 Score: {avg_bleu:.4f}\")\n",
    "    \n",
    "    # Save results\n",
    "    results_path = os.path.join(config.output_dir, 'evaluation_results.json')\n",
    "    evaluation_summary = {\n",
    "        'avg_bleu_score': avg_bleu,\n",
    "        'num_samples': len(all_results),\n",
    "        'detailed_results': all_results\n",
    "    }\n",
    "    \n",
    "    with open(results_path, 'w') as f:\n",
    "        json.dump(evaluation_summary, f, indent=2)\n",
    "    \n",
    "    logger.info(f\"Results saved to {results_path}\")\n",
    "    \n",
    "    return avg_bleu, all_results\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize configuration\n",
    "    config = ModelConfig()\n",
    "    \n",
    "    # Check if files exist\n",
    "    required_files = [config.train_file, config.val_file, config.test_file]\n",
    "    missing_files = [f for f in required_files if not os.path.exists(f)]\n",
    "    \n",
    "    if missing_files:\n",
    "        logger.error(f\"Missing files: {missing_files}\")\n",
    "        logger.error(\"Please ensure the data split files exist before training.\")\n",
    "    else:\n",
    "        # Initialize trainer\n",
    "        trainer = ModelTrainer(config)\n",
    "        \n",
    "        # Start training\n",
    "        try:\n",
    "            logger.info(\"=\"*60)\n",
    "            logger.info(\"STARTING BASELINE MODEL TRAINING\")\n",
    "            logger.info(\"=\"*60)\n",
    "            logger.info(f\"Configuration:\")\n",
    "            logger.info(f\"  Batch size: {config.batch_size}\")\n",
    "            logger.info(f\"  Learning rate: {config.learning_rate}\")\n",
    "            logger.info(f\"  Number of epochs: {config.num_epochs}\")\n",
    "            logger.info(f\"  Image size: {config.image_size}\")\n",
    "            logger.info(f\"  Max sequence length: {config.max_length}\")\n",
    "            logger.info(\"=\"*60)\n",
    "            \n",
    "            model_path = trainer.train()\n",
    "            \n",
    "            logger.info(\"=\"*60)\n",
    "            logger.info(\"TRAINING COMPLETED SUCCESSFULLY\")\n",
    "            logger.info(\"=\"*60)\n",
    "            logger.info(f\"Best model saved at: {model_path}\")\n",
    "            \n",
    "            # Evaluate model\n",
    "            logger.info(\"Starting evaluation on test set...\")\n",
    "            tokenizer_path = os.path.join(config.output_dir, 'tokenizer.json')\n",
    "            \n",
    "            avg_bleu, results = evaluate_model(model_path, config.test_file, tokenizer_path, config)\n",
    "            \n",
    "            logger.info(\"=\"*60)\n",
    "            logger.info(\"EVALUATION COMPLETED\")\n",
    "            logger.info(\"=\"*60)\n",
    "            logger.info(f\"Average BLEU-1 Score: {avg_bleu:.4f}\")\n",
    "            logger.info(f\"Evaluation results saved to: {config.output_dir}/evaluation_results.json\")\n",
    "            \n",
    "            # Show sample results\n",
    "            logger.info(\"\\nSample Results:\")\n",
    "            logger.info(\"-\" * 40)\n",
    "            for i, result in enumerate(results[:3]):\n",
    "                logger.info(f\"Sample {i+1} (BLEU: {result['bleu_score']:.3f}):\")\n",
    "                logger.info(f\"  Original: {result['original'][:150]}...\")\n",
    "                logger.info(f\"  Generated: {result['generated'][:150]}...\")\n",
    "                logger.info(\"\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Training/Evaluation failed: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
